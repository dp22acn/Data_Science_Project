{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1-sOwu9YCl8egHKyaLsayuVUn0PZs_xum",
      "authorship_tag": "ABX9TyMUaJl8dz9WbDKAKtXY3yfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dp22acn/Data_Science_Project/blob/main/python_code_1_manual_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Required Libraries"
      ],
      "metadata": {
        "id": "4sQNUtAvTh5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-4CcfEuTV06"
      },
      "outputs": [],
      "source": [
        "pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvis\n"
      ],
      "metadata": {
        "id": "R_iFA9xrTZT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "B-qe2HNuT588"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vRazgjUSTscI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "saI5HzveUFWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames = ['Character', 'Alternate Names', 'Role', 'Faction', 'Friends', 'enimies']\n",
        "df_edges = pd.read_csv(\"/content/drive/MyDrive/Mac_data_processed_.csv\", header=None, names=colnames, skiprows=1)\n",
        "print(df_edges.shape)\n",
        "df_edges.head()"
      ],
      "metadata": {
        "id": "dOYVs9BAUMnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "Z8Nog_HW2eqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/drive/MyDrive/Mac_data_processed_.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the data\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "data.info()\n",
        "\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "Mv5gAJWP2TRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Data Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h07skc_Q2zHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nValue Counts for {col}:\")\n",
        "    print(data[col].value_counts())\n"
      ],
      "metadata": {
        "id": "KdkslQmQ28DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = df_edges\n",
        "\n",
        "# Initialize a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes (characters) along with their and faction attributes\n",
        "for _, row in df.iterrows():\n",
        "    character = str(row['Character'])\n",
        "    faction = str(row['Faction']) if pd.notnull(row['Faction']) else 'Unknown'  # If 'Faction' is not present, default to 'Unknown'\n",
        "    role = row.get('Role', 'Unknown')  # If 'Role' is not present, default to 'Unknown'\n",
        "\n",
        "    # Add node with the character, faction, and role attributes\n",
        "    G.add_node(character, faction=faction, role=role)\n",
        "\n",
        "# Add edges based on Friendly Links and Hostile Links with advanced weight calculations\n",
        "for _, row in df.iterrows():\n",
        "    character = str(row['Character'])\n",
        "\n",
        "    # Friendly Links (edges)\n",
        "    if isinstance(row['Friends'], str):\n",
        "        friendly_links = row['Friends'].split(',')\n",
        "        for friend in friendly_links:\n",
        "            friend = friend.strip()\n",
        "            # Using custom logic for edge weight (e.g., frequency of interaction)\n",
        "            weight = row['Friends'].count(friend)  # For example, frequency of mention\n",
        "            if G.has_edge(character, friend):\n",
        "                G[character][friend]['weight'] += weight  # Increase weight based on frequency\n",
        "            else:\n",
        "                G.add_edge(character, friend, relationship='friendly', weight=weight)\n",
        "\n",
        "    # Hostile Links (edges)\n",
        "    if isinstance(row['enimies'], str):\n",
        "        hostile_links = row['enimies'].split(',')\n",
        "        for enemy in hostile_links:\n",
        "            enemy = enemy.strip()\n",
        "            # Using custom logic for edge weight (e.g., frequency of mention)\n",
        "            weight = row['enimies'].count(enemy)  # Frequency of mention\n",
        "            if G.has_edge(character, enemy):\n",
        "                G[character][enemy]['weight'] += weight  # Increase weight based on frequency\n",
        "            else:\n",
        "                G.add_edge(character, enemy, relationship='hostile', weight=weight)\n",
        "\n",
        "# normalize edge weights for better visualization\n",
        "max_weight = max(nx.get_edge_attributes(G, 'weight').values())\n",
        "for u, v, data in G.edges(data=True):\n",
        "    data['weight'] = data['weight'] / max_weight  # Normalize weights to a 0-1 scale\n",
        "\n",
        "# Save the network as a GEXF file\n",
        "gexf_file = \"A_Mahabarata_network.gexf\"\n",
        "nx.write_gexf(G, gexf_file)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(gexf_file)\n"
      ],
      "metadata": {
        "id": "O4OF-Y_iU9kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.density(G)"
      ],
      "metadata": {
        "id": "HD3xxeStbe8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degree_centrality = nx.degree_centrality(G)\n",
        "print(\"Degree Centrality:\", degree_centrality)\n",
        "\n",
        "# 2. Betweenness Centrality\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "print(\"Betweenness Centrality:\", betweenness_centrality)\n",
        "\n",
        "# 3. Closeness Centrality\n",
        "closeness_centrality = nx.closeness_centrality(G)\n",
        "print(\"Closeness Centrality:\", closeness_centrality)\n",
        "\n",
        "# 4. Eigenvector Centrality\n",
        "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "print(\"Eigenvector Centrality:\", eigenvector_centrality)\n",
        "\n",
        "# 5. Clustering Coefficient\n",
        "clustering_coefficient = nx.clustering(G)\n",
        "print(\"Clustering Coefficient:\", clustering_coefficient)\n",
        "average_clustering = nx.average_clustering(G)\n",
        "print(\"Average Clustering Coefficient:\", average_clustering)\n",
        "\n",
        "# 6. Density\n",
        "density = nx.density(G)\n",
        "print(\"Density of the Graph:\", density)\n"
      ],
      "metadata": {
        "id": "G_WjF8fTmuf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Degree Centrality\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "top_degree_centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print(\"Top 5 Nodes by Degree Centrality:\")\n",
        "for node, centrality in top_degree_centrality:\n",
        "    print(f\"Node: {node}, Centrality: {centrality}\")\n",
        "\n",
        "# 2. Betweenness Centrality\n",
        "betweenness_centrality = nx.betweenness_centrality(G)\n",
        "top_betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print(\"\\nTop 5 Nodes by Betweenness Centrality:\")\n",
        "for node, centrality in top_betweenness_centrality:\n",
        "    print(f\"Node: {node}, Centrality: {centrality}\")\n",
        "\n",
        "# 3. Closeness Centrality\n",
        "closeness_centrality = nx.closeness_centrality(G)\n",
        "top_closeness_centrality = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print(\"\\nTop 5 Nodes by Closeness Centrality:\")\n",
        "for node, centrality in top_closeness_centrality:\n",
        "    print(f\"Node: {node}, Centrality: {centrality}\")\n",
        "\n",
        "# 4. Eigenvector Centrality\n",
        "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "top_eigenvector_centrality = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print(\"\\nTop 5 Nodes by Eigenvector Centrality:\")\n",
        "for node, centrality in top_eigenvector_centrality:\n",
        "    print(f\"Node: {node}, Centrality: {centrality}\")\n",
        "\n",
        "# 5. Clustering Coefficient\n",
        "clustering_coefficient = nx.clustering(G)\n",
        "top_clustering_coefficient = sorted(clustering_coefficient.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print(\"\\nTop 5 Nodes by Clustering Coefficient:\")\n",
        "for node, coefficient in top_clustering_coefficient:\n",
        "    print(f\"Node: {node}, Coefficient: {coefficient}\")\n",
        "\n",
        "# 6. Density\n",
        "density = nx.density(G)\n",
        "print(\"\\nDensity of the Graph:\", density)\n",
        "\n",
        "# 7. Average Clustering Coefficient\n",
        "average_clustering = nx.average_clustering(G)\n",
        "print(\"Average Clustering Coefficient:\", average_clustering)\n"
      ],
      "metadata": {
        "id": "drSQluoC3leC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Plot Degree Centrality\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(degree_centrality)), degree_centrality.values(), color='blue', alpha=0.7)\n",
        "plt.title('Degree Centrality')\n",
        "plt.xlabel('Nodes')\n",
        "plt.ylabel('Centrality')\n",
        "plt.xticks(range(len(degree_centrality)), labels=[], rotation=90)  # Remove node names\n",
        "plt.show()\n",
        "\n",
        "# 2. Plot Betweenness Centrality\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(betweenness_centrality)), betweenness_centrality.values(), color='green', alpha=0.7)\n",
        "plt.title('Betweenness Centrality')\n",
        "plt.xlabel('Nodes')\n",
        "plt.ylabel('Centrality')\n",
        "plt.xticks(range(len(betweenness_centrality)), labels=[], rotation=90)  # Remove node names\n",
        "plt.show()\n",
        "\n",
        "# 3. Plot Closeness Centrality\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(closeness_centrality)), closeness_centrality.values(), color='orange', alpha=0.7)\n",
        "plt.title('Closeness Centrality')\n",
        "plt.xlabel('Nodes')\n",
        "plt.ylabel('Centrality')\n",
        "plt.xticks(range(len(closeness_centrality)), labels=[], rotation=90)  # Remove node names\n",
        "plt.show()\n",
        "\n",
        "# 4. Plot Eigenvector Centrality\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(eigenvector_centrality)), eigenvector_centrality.values(), color='purple', alpha=0.7)\n",
        "plt.title('Eigenvector Centrality')\n",
        "plt.xlabel('Nodes')\n",
        "plt.ylabel('Centrality')\n",
        "plt.xticks(range(len(eigenvector_centrality)), labels=[], rotation=90)  # Remove node names\n",
        "plt.show()\n",
        "\n",
        "# 5. Clustering Coefficient\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(clustering_coefficient)), clustering_coefficient.values(), color='cyan', alpha=0.7)\n",
        "plt.title('Clustering Coefficient')\n",
        "plt.xlabel('Nodes')\n",
        "plt.ylabel('Coefficient')\n",
        "plt.xticks(range(len(clustering_coefficient)), labels=[], rotation=90)  # Remove node names\n",
        "plt.show()\n",
        "\n",
        "# 6. Average Clustering Coefficient and Density (Pie Chart)\n",
        "metrics = ['Average Clustering Coefficient', 'Density']\n",
        "values = [average_clustering, density]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(values, labels=metrics, autopct='%1.2f%%', colors=['pink', 'lightgreen'], startangle=90)\n",
        "plt.title('Graph Metrics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aKCpbUoLm9w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate triads for a directed graph\n",
        "triadic_census = nx.triadic_census(G)\n",
        "print(\"Triadic Census for Directed Graph:\", triadic_census)\n",
        "\n",
        "# Convert the directed graph to undirected for triangle calculations\n",
        "G_undirected = G.to_undirected()\n",
        "\n",
        "# Calculate the number of triangles per node\n",
        "triangle_counts = nx.triangles(G_undirected)\n",
        "print(\"Triangle Counts per Node:\", triangle_counts)\n",
        "\n",
        "# Calculate the total number of triangles in the graph\n",
        "total_triangles = sum(triangle_counts.values()) // 3  # Each triangle is counted thrice\n",
        "print(\"Total Number of Triangles:\", total_triangles)\n",
        "\n",
        "# Additional insights: Clustering coefficient\n",
        "clustering_coefficient = nx.clustering(G_undirected)\n",
        "print(\"Clustering Coefficient per Node:\", clustering_coefficient)\n",
        "\n",
        "# Average clustering coefficient\n",
        "average_clustering = nx.average_clustering(G_undirected)\n",
        "print(\"Average Clustering Coefficient:\", average_clustering)\n"
      ],
      "metadata": {
        "id": "zry5Mt1LnewL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert triadic census dictionary to lists for plotting\n",
        "triad_types = list(triadic_census.keys())\n",
        "triad_counts = list(triadic_census.values())\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=triad_types, y=triad_counts, palette=\"viridis\")\n",
        "plt.title(\"Triadic Census Distribution\")\n",
        "plt.xlabel(\"Triad Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4lzhr7VFniU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.write_gexf(G, \"A_Mahabarata_network_with_triads.gexf\")\n",
        "files.download(\"A_Mahabarata_network_with_triads.gexf\")\n"
      ],
      "metadata": {
        "id": "It4zG4OMntYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the size for Draupadi (Node size based on relationships)\n",
        "draupadi_node = \"Draupadi\"\n",
        "\n",
        "# 1. Size based on all relationships (all edges)\n",
        "all_relations = len(list(G.neighbors(draupadi_node)))  # All friendly and hostile links\n",
        "\n",
        "# 2. Size based on hostile relationships (edges where relationship='hostile')\n",
        "hostile_relations = sum(1 for _, _, data in G.out_edges(draupadi_node, data=True) if data['relationship'] == 'hostile')\n",
        "\n",
        "# 3. Size based on friendly relationships (edges where relationship='friendly')\n",
        "friendly_relations = sum(1 for _, _, data in G.out_edges(draupadi_node, data=True) if data['relationship'] == 'friendly')\n",
        "\n",
        "# Output the results\n",
        "print(f\"Draupadi's total relations (all): {all_relations}\")\n",
        "print(f\"Draupadi's hostile relations: {hostile_relations}\")\n",
        "print(f\"Draupadi's friendly relations: {friendly_relations}\")"
      ],
      "metadata": {
        "id": "C3Uo9-Dv4iqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvwu7c_wWllV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}